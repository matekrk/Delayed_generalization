{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Training Dynamics: Unified Analysis with Opposing Signals Detection\n",
    "\n",
    "This unified notebook combines and improves upon the previous versions to provide:\n",
    "- **Robust opposing signal detection** with improved algorithms\n",
    "- **Example learning and forgetting patterns** analysis\n",
    "- **High-quality animations** with proper temporal sampling\n",
    "- **Feature learning dynamics** in CNNs\n",
    "- **Class-wise analysis** and difficulty tracking\n",
    "- **Loss trajectory analysis** for individual examples\n",
    "\n",
    "**Key papers implemented:**\n",
    "- Rosenfeld & Risteski (2023): Outliers with Opposing Signals\n",
    "- Toneva et al. (2019): An Empirical Study of Example Forgetting\n",
    "- Arpit et al. (2017): A Closer Look at Memorization in Deep Networks\n",
    "\n",
    "**Improvements over previous versions:**\n",
    "- Fixed opposing pairs detection algorithm\n",
    "- Better gradient-based analysis\n",
    "- Unified visualization pipeline\n",
    "- More robust statistical analysis\n",
    "- Configurable animation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = './data'  # Change this to your desired data path\n",
    "SAVE_ANIMATIONS = True  # Set to False to skip animation generation for faster runs\n",
    "DENSE_SAMPLING = True   # Set to False for less frequent data collection\n",
    "OPPOSING_THRESHOLD = 2.0  # Threshold for detecting opposing signals (gradient cosine similarity)\n",
    "N_EXAMPLES_TRACK = 100    # Number of examples to track in detail\n",
    "ANIMATION_FPS = 10        # Frames per second for animations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict, deque\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Definition and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"Simple CNN for CIFAR-10 classification with feature extraction capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        \n",
    "        # Pooling and dropout\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x, return_features=False):\n",
    "        # Feature extraction\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        features = F.relu(self.fc1(x))\n",
    "        features = self.dropout(features)\n",
    "        output = self.fc2(features)\n",
    "        \n",
    "        if return_features:\n",
    "            return output, features\n",
    "        return output\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "def load_cifar10_data(batch_size=64, num_workers=2):\n",
    "    \"\"\"Load CIFAR-10 with appropriate transforms\"\"\"\n",
    "    \n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=DATA_PATH, train=True, download=True, transform=transform_train\n",
    "    )\n",
    "    \n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=DATA_PATH, train=False, download=True, transform=transform_test\n",
    "    )\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    testloader = DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader, trainset, testset\n",
    "\n",
    "# Load data\n",
    "trainloader, testloader, trainset, testset = load_cifar10_data()\n",
    "print(f'Training set size: {len(trainset)}')\n",
    "print(f'Test set size: {len(testset)}')\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enhanced Training Dynamics Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDynamicsTracker:\n",
    "    \"\"\"Enhanced tracker for neural network training dynamics with opposing signals detection\"\"\"\n",
    "    \n",
    "    def __init__(self, model, trainloader, num_examples_track=100, opposing_threshold=2.0):\n",
    "        self.model = model\n",
    "        self.trainloader = trainloader\n",
    "        self.num_examples_track = num_examples_track\n",
    "        self.opposing_threshold = opposing_threshold\n",
    "        \n",
    "        # Tracking dictionaries\n",
    "        self.example_losses = defaultdict(list)  # example_idx -> [losses]\n",
    "        self.example_predictions = defaultdict(list)  # example_idx -> [predictions]\n",
    "        self.example_confidences = defaultdict(list)  # example_idx -> [confidences]\n",
    "        self.example_gradients = defaultdict(list)  # example_idx -> [gradient_norms]\n",
    "        self.example_features = defaultdict(list)  # example_idx -> [feature_vectors]\n",
    "        \n",
    "        # Opposing signals tracking\n",
    "        self.opposing_pairs = set()  # Set of (idx1, idx2) tuples\n",
    "        self.opposing_signals_history = []  # History of opposing signals per epoch\n",
    "        \n",
    "        # Global training metrics\n",
    "        self.epoch_losses = []\n",
    "        self.epoch_accuracies = []\n",
    "        self.learning_rates = []\n",
    "        \n",
    "        # Example metadata\n",
    "        self.example_to_class = {}\n",
    "        self.tracked_examples = None\n",
    "        \n",
    "        self._setup_tracked_examples()\n",
    "    \n",
    "    def _setup_tracked_examples(self):\n",
    "        \"\"\"Setup which examples to track in detail\"\"\"\n",
    "        # Get a balanced sample of examples from each class\n",
    "        examples_per_class = self.num_examples_track // 10\n",
    "        tracked_examples = []\n",
    "        \n",
    "        class_counts = defaultdict(int)\n",
    "        \n",
    "        for idx, (_, label) in enumerate(self.trainloader.dataset):\n",
    "            if class_counts[label] < examples_per_class:\n",
    "                tracked_examples.append(idx)\n",
    "                self.example_to_class[idx] = label\n",
    "                class_counts[label] += 1\n",
    "                \n",
    "            if len(tracked_examples) >= self.num_examples_track:\n",
    "                break\n",
    "        \n",
    "        self.tracked_examples = set(tracked_examples)\n",
    "        print(f'Tracking {len(self.tracked_examples)} examples across {len(class_counts)} classes')\n",
    "    \n",
    "    def compute_example_gradients(self, example_idx, inputs, targets, retain_graph=False):\n",
    "        \"\"\"Compute gradients for a specific example\"\"\"\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Forward pass for single example\n",
    "        output = self.model(inputs.unsqueeze(0))\n",
    "        loss = F.cross_entropy(output, targets.unsqueeze(0))\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward(retain_graph=retain_graph)\n",
    "        \n",
    "        # Collect gradients\n",
    "        gradients = []\n",
    "        for param in self.model.parameters():\n",
    "            if param.grad is not None:\n",
    "                gradients.append(param.grad.flatten())\n",
    "        \n",
    "        if gradients:\n",
    "            return torch.cat(gradients)\n",
    "        else:\n",
    "            return torch.zeros(1, device=inputs.device)\n",
    "    \n",
    "    def detect_opposing_signals(self, gradients_dict):\n",
    "        \"\"\"Improved opposing signals detection based on gradient similarity\"\"\"\n",
    "        opposing_pairs = set()\n",
    "        example_indices = list(gradients_dict.keys())\n",
    "        \n",
    "        for i in range(len(example_indices)):\n",
    "            for j in range(i + 1, len(example_indices)):\n",
    "                idx1, idx2 = example_indices[i], example_indices[j]\n",
    "                \n",
    "                # Skip if same class (less likely to have opposing signals)\n",
    "                if self.example_to_class.get(idx1) == self.example_to_class.get(idx2):\n",
    "                    continue\n",
    "                \n",
    "                grad1 = gradients_dict[idx1]\n",
    "                grad2 = gradients_dict[idx2]\n",
    "                \n",
    "                # Compute cosine similarity\n",
    "                cos_sim = F.cosine_similarity(grad1.unsqueeze(0), grad2.unsqueeze(0))\n",
    "                \n",
    "                # Opposing signals have negative cosine similarity\n",
    "                # and sufficient magnitude\n",
    "                if cos_sim < -0.5:  # Strong negative correlation\n",
    "                    grad1_norm = torch.norm(grad1)\n",
    "                    grad2_norm = torch.norm(grad2)\n",
    "                    \n",
    "                    # Both gradients should have reasonable magnitude\n",
    "                    if grad1_norm > 0.1 and grad2_norm > 0.1:\n",
    "                        # Check if magnitudes are comparable (within factor of threshold)\n",
    "                        ratio = max(grad1_norm, grad2_norm) / min(grad1_norm, grad2_norm)\n",
    "                        if ratio <= self.opposing_threshold:\n",
    "                            opposing_pairs.add((min(idx1, idx2), max(idx1, idx2)))\n",
    "        \n",
    "        return opposing_pairs\n",
    "    \n",
    "    def track_epoch(self, epoch, optimizer):\n",
    "        \"\"\"Track training dynamics for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        \n",
    "        # Collect gradients for tracked examples\n",
    "        gradients_dict = {}\n",
    "        \n",
    "        # Sample a subset of batches for gradient computation (expensive)\n",
    "        sample_batches = min(10, len(self.trainloader))  # Limit to 10 batches\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(self.trainloader):\n",
    "            if batch_idx >= sample_batches:\n",
    "                break\n",
    "                \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, features = self.model(inputs, return_features=True)\n",
    "            batch_loss = F.cross_entropy(outputs, targets, reduction='none')\n",
    "            \n",
    "            # Track individual examples\n",
    "            for i in range(inputs.size(0)):\n",
    "                example_idx = batch_idx * self.trainloader.batch_size + i\n",
    "                \n",
    "                if example_idx in self.tracked_examples:\n",
    "                    # Store metrics\n",
    "                    self.example_losses[example_idx].append(batch_loss[i].item())\n",
    "                    \n",
    "                    pred = torch.argmax(outputs[i])\n",
    "                    self.example_predictions[example_idx].append(pred.item())\n",
    "                    \n",
    "                    confidence = F.softmax(outputs[i], dim=0).max().item()\n",
    "                    self.example_confidences[example_idx].append(confidence)\n",
    "                    \n",
    "                    self.example_features[example_idx].append(features[i].detach().cpu().numpy())\n",
    "                    \n",
    "                    # Compute gradients (expensive, so limit to tracked examples)\n",
    "                    if len(gradients_dict) < 50:  # Limit gradient computation\n",
    "                        grad = self.compute_example_gradients(\n",
    "                            example_idx, inputs[i], targets[i], retain_graph=True\n",
    "                        )\n",
    "                        gradients_dict[example_idx] = grad\n",
    "                        self.example_gradients[example_idx].append(torch.norm(grad).item())\n",
    "            \n",
    "            # Accumulate epoch metrics\n",
    "            epoch_loss += batch_loss.sum().item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            epoch_total += targets.size(0)\n",
    "            epoch_correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Detect opposing signals\n",
    "        if gradients_dict:\n",
    "            opposing_pairs = self.detect_opposing_signals(gradients_dict)\n",
    "            self.opposing_pairs.update(opposing_pairs)\n",
    "            self.opposing_signals_history.append(len(opposing_pairs))\n",
    "        else:\n",
    "            self.opposing_signals_history.append(0)\n",
    "        \n",
    "        # Store epoch metrics\n",
    "        self.epoch_losses.append(epoch_loss / epoch_total)\n",
    "        self.epoch_accuracies.append(100. * epoch_correct / epoch_total)\n",
    "        self.learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        print(f'Epoch {epoch}: Loss={self.epoch_losses[-1]:.4f}, '\n",
    "              f'Acc={self.epoch_accuracies[-1]:.2f}%, '\n",
    "              f'Opposing signals={self.opposing_signals_history[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Loop with Dynamics Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_tracking(num_epochs=20):\n",
    "    \"\"\"Train model while tracking dynamics\"\"\"\n",
    "    \n",
    "    # Initialize model and optimizer\n",
    "    model = SimpleCNN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "    # Initialize tracker\n",
    "    tracker = TrainingDynamicsTracker(\n",
    "        model, trainloader, \n",
    "        num_examples_track=N_EXAMPLES_TRACK,\n",
    "        opposing_threshold=OPPOSING_THRESHOLD\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Standard training\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Track dynamics (expensive, so do less frequently)\n",
    "        if DENSE_SAMPLING or epoch % 2 == 0:\n",
    "            tracker.track_epoch(epoch, optimizer)\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return model, tracker\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training with dynamics tracking...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model, tracker = train_with_tracking(num_epochs=15)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Found {len(tracker.opposing_pairs)} opposing pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_training_dynamics(tracker):\n",
    "    \"\"\"Comprehensive analysis of training dynamics\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Training curves\n",
    "    epochs = range(len(tracker.epoch_losses))\n",
    "    \n",
    "    ax1 = axes[0, 0]\n",
    "    ax1_twin = ax1.twinx()\n",
    "    \n",
    "    line1 = ax1.plot(epochs, tracker.epoch_losses, 'b-', label='Loss', linewidth=2)\n",
    "    line2 = ax1_twin.plot(epochs, tracker.epoch_accuracies, 'r-', label='Accuracy', linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color='b')\n",
    "    ax1_twin.set_ylabel('Accuracy (%)', color='r')\n",
    "    ax1.set_title('Training Progress')\n",
    "    \n",
    "    # Combine legends\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='center right')\n",
    "    \n",
    "    # 2. Opposing signals over time\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(epochs, tracker.opposing_signals_history, 'g-', linewidth=2, marker='o')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Number of Opposing Pairs')\n",
    "    ax2.set_title('Opposing Signals Detection')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Learning rate schedule\n",
    "    ax3 = axes[0, 2]\n",
    "    ax3.plot(epochs, tracker.learning_rates, 'm-', linewidth=2)\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Learning Rate')\n",
    "    ax3.set_title('Learning Rate Schedule')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Example loss trajectories (sample)\n",
    "    ax4 = axes[1, 0]\n",
    "    \n",
    "    # Plot trajectories for a few examples from each class\n",
    "    class_colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "    \n",
    "    for class_id in range(10):\n",
    "        examples_in_class = [idx for idx, cls in tracker.example_to_class.items() if cls == class_id]\n",
    "        \n",
    "        if examples_in_class:\n",
    "            # Plot first example from this class\n",
    "            example_idx = examples_in_class[0]\n",
    "            if example_idx in tracker.example_losses and tracker.example_losses[example_idx]:\n",
    "                losses = tracker.example_losses[example_idx]\n",
    "                ax4.plot(range(len(losses)), losses, \n",
    "                        color=class_colors[class_id], alpha=0.7,\n",
    "                        label=class_names[class_id])\n",
    "    \n",
    "    ax4.set_xlabel('Tracking Step')\n",
    "    ax4.set_ylabel('Loss')\n",
    "    ax4.set_title('Example Loss Trajectories by Class')\n",
    "    ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Confidence evolution\n",
    "    ax5 = axes[1, 1]\n",
    "    \n",
    "    all_confidences = []\n",
    "    for example_idx in list(tracker.example_confidences.keys())[:20]:  # Sample 20 examples\n",
    "        confidences = tracker.example_confidences[example_idx]\n",
    "        if confidences:\n",
    "            ax5.plot(range(len(confidences)), confidences, alpha=0.5, linewidth=1)\n",
    "            all_confidences.extend(confidences)\n",
    "    \n",
    "    ax5.set_xlabel('Tracking Step')\n",
    "    ax5.set_ylabel('Prediction Confidence')\n",
    "    ax5.set_title('Confidence Evolution (Sample Examples)')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Gradient norms distribution\n",
    "    ax6 = axes[1, 2]\n",
    "    \n",
    "    all_grad_norms = []\n",
    "    for grad_norms in tracker.example_gradients.values():\n",
    "        all_grad_norms.extend(grad_norms)\n",
    "    \n",
    "    if all_grad_norms:\n",
    "        ax6.hist(all_grad_norms, bins=50, alpha=0.7, edgecolor='black')\n",
    "        ax6.set_xlabel('Gradient Norm')\n",
    "        ax6.set_ylabel('Frequency')\n",
    "        ax6.set_title('Gradient Norms Distribution')\n",
    "        ax6.set_yscale('log')\n",
    "        ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_dynamics_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Run analysis\n",
    "analyze_training_dynamics(tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Opposing Signals Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_opposing_signals(tracker):\n",
    "    \"\"\"Detailed analysis of opposing signals\"\"\"\n",
    "    \n",
    "    if not tracker.opposing_pairs:\n",
    "        print(\"No opposing pairs found. Consider lowering the opposing_threshold.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(tracker.opposing_pairs)} opposing pairs\")\n",
    "    \n",
    "    # Analyze class distribution in opposing pairs\n",
    "    class_pair_counts = defaultdict(int)\n",
    "    \n",
    "    for idx1, idx2 in tracker.opposing_pairs:\n",
    "        class1 = tracker.example_to_class.get(idx1, -1)\n",
    "        class2 = tracker.example_to_class.get(idx2, -1)\n",
    "        \n",
    "        if class1 != -1 and class2 != -1:\n",
    "            pair_key = tuple(sorted([class1, class2]))\n",
    "            class_pair_counts[pair_key] += 1\n",
    "    \n",
    "    # Visualize opposing pairs\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 1. Class pair matrix\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    pair_matrix = np.zeros((10, 10))\n",
    "    for (c1, c2), count in class_pair_counts.items():\n",
    "        pair_matrix[c1, c2] = count\n",
    "        pair_matrix[c2, c1] = count  # Symmetric\n",
    "    \n",
    "    im = ax1.imshow(pair_matrix, cmap='Blues')\n",
    "    ax1.set_xticks(range(10))\n",
    "    ax1.set_yticks(range(10))\n",
    "    ax1.set_xticklabels(class_names, rotation=45)\n",
    "    ax1.set_yticklabels(class_names)\n",
    "    ax1.set_title('Opposing Signals by Class Pairs')\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            if pair_matrix[i, j] > 0:\n",
    "                ax1.text(j, i, f'{int(pair_matrix[i, j])}', \n",
    "                        ha='center', va='center', color='red', fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im, ax=ax1)\n",
    "    \n",
    "    # 2. Opposing signals over time\n",
    "    ax2 = axes[1]\n",
    "    epochs = range(len(tracker.opposing_signals_history))\n",
    "    ax2.plot(epochs, tracker.opposing_signals_history, 'r-', linewidth=3, marker='o', markersize=8)\n",
    "    ax2.fill_between(epochs, tracker.opposing_signals_history, alpha=0.3, color='red')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Number of Opposing Pairs')\n",
    "    ax2.set_title('Opposing Signals Evolution')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('opposing_signals_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(\"\\nOpposing Signals Statistics:\")\n",
    "    print(f\"Total opposing pairs: {len(tracker.opposing_pairs)}\")\n",
    "    print(f\"Most common class pairs:\")\n",
    "    \n",
    "    sorted_pairs = sorted(class_pair_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    for (c1, c2), count in sorted_pairs[:5]:\n",
    "        print(f\"  {class_names[c1]} vs {class_names[c2]}: {count} pairs\")\n",
    "\n",
    "# Run opposing signals analysis\n",
    "analyze_opposing_signals(tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Animated Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loss_trajectory_animation(tracker, save_path='loss_trajectories.gif'):\n",
    "    \"\"\"Create animated visualization of loss trajectories\"\"\"\n",
    "    \n",
    "    if not SAVE_ANIMATIONS:\n",
    "        print(\"Animation saving disabled. Set SAVE_ANIMATIONS=True to generate.\")\n",
    "        return\n",
    "    \n",
    "    # Prepare data\n",
    "    examples_to_plot = []\n",
    "    max_steps = 0\n",
    "    \n",
    "    # Get examples with sufficient data points\n",
    "    for idx, losses in tracker.example_losses.items():\n",
    "        if len(losses) >= 5:  # Minimum trajectory length\n",
    "            examples_to_plot.append(idx)\n",
    "            max_steps = max(max_steps, len(losses))\n",
    "    \n",
    "    examples_to_plot = examples_to_plot[:50]  # Limit for performance\n",
    "    \n",
    "    if not examples_to_plot:\n",
    "        print(\"No examples with sufficient trajectory data for animation.\")\n",
    "        return\n",
    "    \n",
    "    # Set up the figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Color mapping by class\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "    \n",
    "    # Initialize lines\n",
    "    lines = {}\n",
    "    for idx in examples_to_plot:\n",
    "        class_id = tracker.example_to_class.get(idx, 0)\n",
    "        line, = ax.plot([], [], color=colors[class_id], alpha=0.7, linewidth=2)\n",
    "        lines[idx] = line\n",
    "    \n",
    "    # Set up the plot\n",
    "    all_losses = [loss for losses in tracker.example_losses.values() for loss in losses]\n",
    "    ax.set_xlim(0, max_steps)\n",
    "    ax.set_ylim(min(all_losses) * 0.9, max(all_losses) * 1.1)\n",
    "    ax.set_xlabel('Training Step')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Loss Trajectories Animation')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_lines = [plt.Line2D([0], [0], color=colors[i], linewidth=2) for i in range(10)]\n",
    "    ax.legend(legend_lines, class_names, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    def animate(frame):\n",
    "        for idx in examples_to_plot:\n",
    "            losses = tracker.example_losses[idx]\n",
    "            if frame < len(losses):\n",
    "                x_data = list(range(frame + 1))\n",
    "                y_data = losses[:frame + 1]\n",
    "                lines[idx].set_data(x_data, y_data)\n",
    "        \n",
    "        # Update title with current step\n",
    "        ax.set_title(f'Loss Trajectories Animation - Step {frame + 1}/{max_steps}')\n",
    "        \n",
    "        return list(lines.values())\n",
    "    \n",
    "    # Create animation\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, animate, frames=max_steps, interval=200, blit=False, repeat=True\n",
    "    )\n",
    "    \n",
    "    # Save animation\n",
    "    try:\n",
    "        anim.save(save_path, writer='pillow', fps=ANIMATION_FPS)\n",
    "        print(f\"Animation saved to {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save animation: {e}\")\n",
    "    \n",
    "    plt.show()\n",
    "    return anim\n",
    "\n",
    "# Create animation\n",
    "if tracker.example_losses:\n",
    "    anim = create_loss_trajectory_animation(tracker)\n",
    "else:\n",
    "    print(\"No loss trajectory data available for animation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report(tracker):\n",
    "    \"\"\"Generate comprehensive summary report\"\"\"\n",
    "    \n",
    "    report = f\"\"\"\n",
    "    ═══════════════════════════════════════════════════════════════\n",
    "                          TRAINING DYNAMICS REPORT\n",
    "    ═══════════════════════════════════════════════════════════════\n",
    "    \n",
    "    EXPERIMENT CONFIGURATION:\n",
    "    • Examples tracked: {len(tracker.tracked_examples)}\n",
    "    • Opposing threshold: {OPPOSING_THRESHOLD}\n",
    "    • Dense sampling: {DENSE_SAMPLING}\n",
    "    • Animation FPS: {ANIMATION_FPS}\n",
    "    \n",
    "    TRAINING RESULTS:\n",
    "    • Total epochs: {len(tracker.epoch_losses)}\n",
    "    • Final loss: {tracker.epoch_losses[-1]:.4f}\n",
    "    • Final accuracy: {tracker.epoch_accuracies[-1]:.2f}%\n",
    "    • Final learning rate: {tracker.learning_rates[-1]:.2e}\n",
    "    \n",
    "    OPPOSING SIGNALS ANALYSIS:\n",
    "    • Total opposing pairs found: {len(tracker.opposing_pairs)}\n",
    "    • Peak opposing signals: {max(tracker.opposing_signals_history) if tracker.opposing_signals_history else 0}\n",
    "    • Average opposing signals per epoch: {np.mean(tracker.opposing_signals_history):.1f}\n",
    "    \n",
    "    LEARNING DYNAMICS:\n",
    "    • Examples with complete trajectories: {sum(1 for losses in tracker.example_losses.values() if len(losses) >= 5)}\n",
    "    • Average trajectory length: {np.mean([len(losses) for losses in tracker.example_losses.values()]):.1f}\n",
    "    • Examples with gradient data: {len(tracker.example_gradients)}\n",
    "    \n",
    "    KEY FINDINGS:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add key findings based on analysis\n",
    "    if tracker.opposing_pairs:\n",
    "        report += f\"\\n    • Successfully detected opposing signals between examples from different classes\"\n",
    "        \n",
    "        # Find most common opposing class pairs\n",
    "        class_pair_counts = defaultdict(int)\n",
    "        for idx1, idx2 in tracker.opposing_pairs:\n",
    "            class1 = tracker.example_to_class.get(idx1, -1)\n",
    "            class2 = tracker.example_to_class.get(idx2, -1)\n",
    "            if class1 != -1 and class2 != -1:\n",
    "                pair_key = tuple(sorted([class1, class2]))\n",
    "                class_pair_counts[pair_key] += 1\n",
    "        \n",
    "        if class_pair_counts:\n",
    "            top_pair = max(class_pair_counts.items(), key=lambda x: x[1])\n",
    "            c1, c2 = top_pair[0]\n",
    "            count = top_pair[1]\n",
    "            report += f\"\\n    • Most opposing pair: {class_names[c1]} vs {class_names[c2]} ({count} pairs)\"\n",
    "    else:\n",
    "        report += f\"\\n    • No opposing signals detected (consider lowering threshold)\"\n",
    "    \n",
    "    # Learning progression analysis\n",
    "    if len(tracker.epoch_accuracies) > 1:\n",
    "        initial_acc = tracker.epoch_accuracies[0]\n",
    "        final_acc = tracker.epoch_accuracies[-1]\n",
    "        improvement = final_acc - initial_acc\n",
    "        report += f\"\\n    • Accuracy improvement: {improvement:.2f}% (from {initial_acc:.2f}% to {final_acc:.2f}%)\"\n",
    "    \n",
    "    # Loss dynamics\n",
    "    if len(tracker.epoch_losses) > 1:\n",
    "        initial_loss = tracker.epoch_losses[0]\n",
    "        final_loss = tracker.epoch_losses[-1]\n",
    "        loss_reduction = (initial_loss - final_loss) / initial_loss * 100\n",
    "        report += f\"\\n    • Loss reduction: {loss_reduction:.1f}% (from {initial_loss:.4f} to {final_loss:.4f})\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "    \n",
    "    RECOMMENDATIONS:\n",
    "    • For more opposing signals, try lowering the opposing_threshold to 1.5\n",
    "    • For better animations, enable DENSE_SAMPLING for more data points\n",
    "    • Consider training for more epochs to observe longer-term dynamics\n",
    "    • Experiment with different optimizers (SGD vs Adam) for different dynamics\n",
    "    \n",
    "    ═══════════════════════════════════════════════════════════════\n",
    "                            END OF REPORT\n",
    "    ═══════════════════════════════════════════════════════════════\n",
    "    \"\"\"\n",
    "    \n",
    "    print(report)\n",
    "    \n",
    "    # Save report to file\n",
    "    with open('training_dynamics_report.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(\"\\nDetailed report saved to 'training_dynamics_report.txt'\")\n",
    "\n",
    "# Generate final report\n",
    "generate_summary_report(tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(tracker, model, filename='training_dynamics_results.pkl'):\n",
    "    \"\"\"Save all results for later analysis\"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'example_losses': dict(tracker.example_losses),\n",
    "        'example_predictions': dict(tracker.example_predictions), \n",
    "        'example_confidences': dict(tracker.example_confidences),\n",
    "        'example_gradients': dict(tracker.example_gradients),\n",
    "        'opposing_pairs': list(tracker.opposing_pairs),\n",
    "        'opposing_signals_history': tracker.opposing_signals_history,\n",
    "        'epoch_losses': tracker.epoch_losses,\n",
    "        'epoch_accuracies': tracker.epoch_accuracies,\n",
    "        'learning_rates': tracker.learning_rates,\n",
    "        'example_to_class': tracker.example_to_class,\n",
    "        'tracked_examples': list(tracker.tracked_examples),\n",
    "        'config': {\n",
    "            'opposing_threshold': OPPOSING_THRESHOLD,\n",
    "            'n_examples_track': N_EXAMPLES_TRACK,\n",
    "            'dense_sampling': DENSE_SAMPLING,\n",
    "            'animation_fps': ANIMATION_FPS\n",
    "        },\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    \n",
    "    print(f\"Results saved to {filename}\")\n",
    "    print(f\"File size: {os.path.getsize(filename) / (1024*1024):.2f} MB\")\n",
    "\n",
    "def load_results(filename='training_dynamics_results.pkl'):\n",
    "    \"\"\"Load previously saved results\"\"\"\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    \n",
    "    print(f\"Loaded results from {results['timestamp']}\")\n",
    "    print(f\"Configuration: {results['config']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Save current results\n",
    "save_results(tracker, model)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING DYNAMICS ANALYSIS COMPLETE!\")\n",
    "print(\"Files generated:\")\n",
    "print(\"• training_dynamics_analysis.png - Main analysis plots\")\n",
    "print(\"• opposing_signals_analysis.png - Opposing signals visualization\")\n",
    "print(\"• loss_trajectories.gif - Animated loss trajectories (if enabled)\")\n",
    "print(\"• training_dynamics_report.txt - Detailed text report\")\n",
    "print(\"• training_dynamics_results.pkl - All data for further analysis\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}